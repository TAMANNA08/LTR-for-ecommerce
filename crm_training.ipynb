{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "from model import cnn_model\n",
    "from utils import batch_gen\n",
    "from evaluation_metrics import get_trec_eval_metrics\n",
    "from tensorflow.keras.backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAGRANGE_MULTIPLIER = 0.01\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "PATIENCE = 2\n",
    "MODEL_DIR = ''\n",
    "LOG_DIR = ''\n",
    "INPUT_DATA_PATH = ''\n",
    "MODEL_NAME = 'click_logs'\n",
    "TREC_EVAL_PATH = \"/trec_eval\"\n",
    "OUTPUT_FREQUENCY = 10000 #number of batches to be processed before printing dev metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(INPUT_DATA_PATH, 'click_rel_train.csv')\n",
    "dev_data = pd.read_csv(os.path.join(INPUT_DATA_PATH, 'click_rel_dev.csv')\n",
    "test_data = pd.read_csv(os.path.join(INPUT_DATA_PATH, 'click_rel_test.csv')\n",
    "\n",
    "embeddings = np.load(os.path.join(INPUT_DATA_PATH, 'embedding.npy')\n",
    "\n",
    "q_train = np.load(os.path.join(INPUT_DATA_PATH, 'queries_train.npy'))\n",
    "a_train = np.load(os.path.join(INPUT_DATA_PATH, 'products_train.npy'))\n",
    "\n",
    "qids_train = train_data['qid']\n",
    "loss_train = train_data['loss']\n",
    "action_train = train_data['action']\n",
    "addn_feat_train = np.array(train_data['addn_feat'].apply(lambda x: [float(elem) for elem in x.split(', ')]).tolist())\n",
    "probs_train = train_data['control_policy_prob']\n",
    "\n",
    "print('''q_train.shape, a_train.shape, qids_train.shape, addn_feat_train.shape: ''')\n",
    "print(q_train.shape, q_train.shape, qids_train.shape, addn_feat_train.shape)\n",
    "\n",
    "q_dev = np.load(os.path.join(INPUT_DATA_PATH, 'queries_dev.npy'))\n",
    "a_dev = np.load(os.path.join(INPUT_DATA_PATH, 'products_dev.npy'))\n",
    "y_dev = dev_data['click_rel']\n",
    "qids_dev = dev_data['qids']\n",
    "addn_feat_dev = np.array(dev_data['addn_feat'].apply(lambda x: [float(elem) for elem in x.split(', ')]).tolist())\n",
    "\n",
    "q_test = np.load(os.path.join(INPUT_DATA_PATH, 'queries_test.npy'))\n",
    "a_test = np.load(os.path.join(INPUT_DATA_PATH, 'products_test.npy'))\n",
    "y_test = test_data['click_rel']\n",
    "qids_test = test_data['qids']\n",
    "addn_feat_test = np.array(test_data['addn_feat'].apply(lambda x: [float(elem) for elem in x.split(', ')]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "addit_feat_len = 1\n",
    "if addn_feat_train.ndim > 1:\n",
    "    addit_feat_len = addn_feat_train.shape[1]\n",
    "\n",
    "embed_dim = embeddings.shape\n",
    "max_ques_len = q_train.shape[1]\n",
    "max_ans_len = a_train.shape[1]\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        set_session(sess)\n",
    "\n",
    "        # Get model\n",
    "        cnn_model_instance = cnn_model(max_ques_len, max_ans_len,  embeddings, addit_feat_len=addit_feat_len)\n",
    "\n",
    "        # Compute weights for the model\n",
    "        weights_train = (loss_train - LAGRANGE_MULTIPLIER)/probs_train \n",
    "\n",
    "        y_pred_dev = cnn_model_instance.predict([q_dev, a_dev, addn_feat_dev, np.ones(shape = len(q_dev))])\n",
    "        map_score_overall, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_dev, y_pred_dev, y_dev, TREC_EVAL_PATH)\n",
    "        print('Initial results on {} set are: MAP: {}, MRR:{}, P@5: {}, P@10: {}, NDCG@5: {}, NDCG@10: {}'\n",
    "              .format('DEV', map_score_overall, mrr, p_5, p_10, ndcg_5, ndcg_10))\n",
    "        y_pred_test = cnn_model_instance.predict([q_test, a_test, addn_feat_test, np.ones(shape = len(q_test))])\n",
    "        map_score, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_test, y_pred_test, y_test, TREC_EVAL_PATH)\n",
    "        print('Initial results on {} set are: MAP: {}, MRR:{}, P@5: {}, P@10: {}, NDCG@5: {}, NDCG@10: {}'\n",
    "              .format('TEST', map_score, mrr, p_5, p_10, ndcg_5, ndcg_10))\n",
    "\n",
    "        patience = 0\n",
    "        best_model_weights = cnn_model_instance.get_weights()\n",
    "\n",
    "        loss_mult_batches = 0 \n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            print('Epoch: ', epoch)\n",
    "\n",
    "            batch_no = 0\n",
    "            num_clicks = 0\n",
    "            for b_q_train, b_a_train, b_addn_feat_train, b_weights, b_action, b_qid in zip(\n",
    "                batch_gen(q_train, BATCH_SIZE), batch_gen(a_train, BATCH_SIZE), \n",
    "                batch_gen(addn_feat_train, BATCH_SIZE), batch_gen(weights_train, BATCH_SIZE),\n",
    "                batch_gen(action_train, BATCH_SIZE), batch_gen(qids_train, BATCH_SIZE)):\n",
    "\n",
    "                loss_batch = cnn_model_instance.train_on_batch([b_q_train, b_a_train, b_addn_feat_train, b_weights], b_action)\n",
    "                loss_mult_batches += loss_batch\n",
    "\n",
    "                if batch_no%OUTPUT_FREQUENCY == 0:\n",
    "\n",
    "                    print('{} batches were already processed'.format(batch_no))     \n",
    "                    print('Average Loss of Last {} batches is: {}'.format(OUTPUT_FREQUENCY, (loss_mult_batches/100)+0.1))\n",
    "                    loss_mult_batches = 0\n",
    "\n",
    "                    # [NOTE] makes training significantly longer\n",
    "                    y_pred_dev = cnn_model_instance.predict([q_dev, a_dev, addn_feat_dev, np.ones(shape = len(q_dev))])\n",
    "                    map_score, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_dev, y_pred_dev, y_dev, TREC_EVAL_PATH)\n",
    "                    print('Results on {} set after {} batches are: MAP: {}, MRR:{}, NDCG@5: {}, NDCG@10: {}'\n",
    "                          .format('DEV', batch_no, map_score, mrr, ndcg_5, ndcg_10))\n",
    "\n",
    "                batch_no += 1\n",
    "                \n",
    "            y_pred_dev = cnn_model_instance.predict([q_dev, a_dev, addn_feat_dev, np.ones(shape = len(q_dev))])\n",
    "            map_score_current, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_dev, y_pred_dev, y_dev, TREC_EVAL_PATH)\n",
    "            print('Results on {} set for epoch {} are: MAP: {}, MRR:{}, NDCG@5: {}, NDCG@10: {}'\n",
    "                  .format('DEV', epoch, map_score_current, mrr, ndcg_5, ndcg_10))    \n",
    "\n",
    "            y_pred_train = cnn_model_instance.predict([q_train, a_train, addn_feat_train, np.ones(shape = len(q_train))])                \n",
    "            y_pred_train[action_train == 0] = 1 - y_pred_train[action_train == 0]\n",
    "            y_pred_train = np.reshape(y_pred_train, (y_pred_train.shape[0], 1))\n",
    "            probs_train = np.reshape(probs_train, (y_pred_train.shape[0], 1))\n",
    "            np.divide(y_pred_train, probs_train, out = y_pred_train)\n",
    "            S_train = np.mean(y_pred_train)\n",
    "            print('S after epoch {} is {}'.format(epoch, S_train))\n",
    "\n",
    "            if map_score_current > map_score_overall or epoch == 0:\n",
    "                map_score_overall = map_score_current\n",
    "                best_model_weights = cnn_model_instance.get_weights()\n",
    "            elif patience < PATIENCE:\n",
    "                patience += 1\n",
    "            else: break\n",
    "\n",
    "        cnn_model_instance.set_weights(best_model_weights)\n",
    "        cnn_model_instance.save(os.path.join(MODEL_DIR, MODEL_NAME+'.h5'))\n",
    "\n",
    "        y_pred_dev = cnn_model_instance.predict([q_dev, a_dev, addn_feat_dev, np.ones(shape = len(q_dev))])\n",
    "        map_score, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_dev, y_pred_dev, y_dev, TREC_EVAL_PATH)\n",
    "        print('BEST results on {} set are: MAP: {}, MRR:{}, P@5: {}, P@10: {}, NDCG@5: {}, NDCG@10: {}'\n",
    "              .format('DEV', map_score, mrr, p_5, p_10, ndcg_5, ndcg_10))\n",
    "        y_pred_test = cnn_model_instance.predict([q_test, a_test, addn_feat_test, np.ones(shape = len(q_test))])\n",
    "        map_score, mrr, p_5, p_10, ndcg_5, ndcg_10 = get_trec_eval_metrics(qids_test, y_pred_test, y_test, TREC_EVAL_PATH)\n",
    "        print('BEST results on {} set are: MAP: {}, MRR:{}, P@5: {}, P@10: {}, NDCG@5: {}, NDCG@10: {}'\n",
    "              .format('TEST', map_score, mrr, p_5, p_10, ndcg_5, ndcg_10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
